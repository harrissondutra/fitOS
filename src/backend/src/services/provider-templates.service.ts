import { AiProviderType } from '../../../shared/types/ai.types'

export interface ProviderTemplate {
  id: string
  name: string
  displayName: string
  provider: AiProviderType
  description: string
  icon: string
  color: string
  models: string[]
  features: string[]
  pricing: {
    model: string
    inputCost: number // per 1K tokens
    outputCost: number // per 1K tokens
  }[]
  capabilities: {
    chat: boolean
    vision: boolean
    audio: boolean
    embeddings: boolean
    functionCalling: boolean
    streaming: boolean
  }
  config: {
    baseUrl?: string
    timeout: number
    maxRetries: number
    headers?: Record<string, string>
  }
  setup: {
    requiresApiKey: boolean
    apiKeyPlaceholder: string
    apiKeyHelp: string
    additionalConfig?: Array<{
      key: string
      label: string
      type: 'text' | 'url' | 'number' | 'boolean'
      placeholder?: string
      help?: string
      required?: boolean
    }>
  }
}

export class ProviderTemplatesService {
  private static templates: ProviderTemplate[] = [
    {
      id: 'openai',
      name: 'OpenAI',
      displayName: 'OpenAI GPT',
      provider: AiProviderType.OPENAI,
      description: 'Modelos GPT-4, GPT-3.5 e DALL-E para conversa√ß√£o, an√°lise de imagens e gera√ß√£o de conte√∫do',
      icon: 'ü§ñ',
      color: 'bg-green-100 text-green-800',
      models: [
        'gpt-4o',
        'gpt-4o-mini',
        'gpt-4-turbo',
        'gpt-4',
        'gpt-3.5-turbo',
        'gpt-3.5-turbo-16k',
        'dall-e-3',
        'dall-e-2',
        'whisper-1',
        'tts-1',
        'tts-1-hd'
      ],
      features: [
        'Conversa√ß√£o avan√ßada',
        'An√°lise de imagens',
        'Gera√ß√£o de imagens',
        'Transcri√ß√£o de √°udio',
        'S√≠ntese de voz',
        'Function calling',
        'Streaming'
      ],
      pricing: [
        { model: 'gpt-4o', inputCost: 0.005, outputCost: 0.015 },
        { model: 'gpt-4o-mini', inputCost: 0.00015, outputCost: 0.0006 },
        { model: 'gpt-4-turbo', inputCost: 0.01, outputCost: 0.03 },
        { model: 'gpt-4', inputCost: 0.03, outputCost: 0.06 },
        { model: 'gpt-3.5-turbo', inputCost: 0.0015, outputCost: 0.002 }
      ],
      capabilities: {
        chat: true,
        vision: true,
        audio: true,
        embeddings: true,
        functionCalling: true,
        streaming: true
      },
      config: {
        baseUrl: 'https://api.openai.com/v1',
        timeout: 30000,
        maxRetries: 3,
        headers: {
          'Content-Type': 'application/json'
        }
      },
      setup: {
        requiresApiKey: true,
        apiKeyPlaceholder: 'sk-...',
        apiKeyHelp: 'Sua chave API do OpenAI. Obtenha em https://platform.openai.com/api-keys',
        additionalConfig: [
          {
            key: 'organization',
            label: 'Organization ID',
            type: 'text',
            placeholder: 'org-...',
            help: 'ID da organiza√ß√£o (opcional)',
            required: false
          }
        ]
      }
    },
    {
      id: 'gemini',
      name: 'Google Gemini',
      displayName: 'Google Gemini',
      provider: AiProviderType.GEMINI,
      description: 'Modelos Gemini Pro e Gemini Pro Vision para conversa√ß√£o multimodal e an√°lise de imagens',
      icon: 'üíé',
      color: 'bg-blue-100 text-blue-800',
      models: [
        'gemini-1.5-pro',
        'gemini-1.5-flash',
        'gemini-1.0-pro',
        'gemini-1.0-pro-vision',
        'gemini-1.5-pro-vision'
      ],
      features: [
        'Conversa√ß√£o multimodal',
        'An√°lise de imagens',
        'Processamento de documentos',
        'Racioc√≠nio avan√ßado',
        'Contexto longo (1M tokens)',
        'Streaming'
      ],
      pricing: [
        { model: 'gemini-1.5-pro', inputCost: 0.00125, outputCost: 0.005 },
        { model: 'gemini-1.5-flash', inputCost: 0.000075, outputCost: 0.0003 },
        { model: 'gemini-1.0-pro', inputCost: 0.0005, outputCost: 0.0015 }
      ],
      capabilities: {
        chat: true,
        vision: true,
        audio: false,
        embeddings: true,
        functionCalling: true,
        streaming: true
      },
      config: {
        baseUrl: 'https://generativelanguage.googleapis.com/v1beta',
        timeout: 30000,
        maxRetries: 3,
        headers: {
          'Content-Type': 'application/json'
        }
      },
      setup: {
        requiresApiKey: true,
        apiKeyPlaceholder: 'AIza...',
        apiKeyHelp: 'Sua chave API do Google AI. Obtenha em https://makersuite.google.com/app/apikey',
        additionalConfig: []
      }
    },
    {
      id: 'groq',
      name: 'Groq',
      displayName: 'Groq (Llama/Mixtral)',
      provider: AiProviderType.GROQ,
      description: 'Modelos Llama 3, Mixtral e Whisper com infer√™ncia ultra-r√°pida para aplica√ß√µes em tempo real',
      icon: '‚ö°',
      color: 'bg-purple-100 text-purple-800',
      models: [
        'llama-3.1-70b-versatile',
        'llama-3.1-8b-instant',
        'llama-3-70b-8192',
        'llama-3-8b-8192',
        'mixtral-8x7b-32768',
        'gemma-7b-it',
        'whisper-large-v3'
      ],
      features: [
        'Infer√™ncia ultra-r√°pida',
        'Modelos open-source',
        'Transcri√ß√£o de √°udio',
        'Streaming',
        'Baixo custo',
        'Alta performance'
      ],
      pricing: [
        { model: 'llama-3.1-70b-versatile', inputCost: 0.00059, outputCost: 0.00079 },
        { model: 'llama-3.1-8b-instant', inputCost: 0.00005, outputCost: 0.00005 },
        { model: 'mixtral-8x7b-32768', inputCost: 0.00027, outputCost: 0.00027 }
      ],
      capabilities: {
        chat: true,
        vision: false,
        audio: true,
        embeddings: false,
        functionCalling: false,
        streaming: true
      },
      config: {
        baseUrl: 'https://api.groq.com/openai/v1',
        timeout: 30000,
        maxRetries: 3,
        headers: {
          'Content-Type': 'application/json'
        }
      },
      setup: {
        requiresApiKey: true,
        apiKeyPlaceholder: 'gsk_...',
        apiKeyHelp: 'Sua chave API do Groq. Obtenha em https://console.groq.com/keys',
        additionalConfig: []
      }
    },
    {
      id: 'claude',
      name: 'Anthropic Claude',
      displayName: 'Anthropic Claude',
      provider: AiProviderType.CLAUDE,
      description: 'Modelos Claude 3 Opus, Sonnet e Haiku para conversa√ß√£o avan√ßada e an√°lise de documentos',
      icon: 'üß†',
      color: 'bg-orange-100 text-orange-800',
      models: [
        'claude-3-5-sonnet-20241022',
        'claude-3-5-haiku-20241022',
        'claude-3-opus-20240229',
        'claude-3-sonnet-20240229',
        'claude-3-haiku-20240307'
      ],
      features: [
        'Conversa√ß√£o avan√ßada',
        'An√°lise de documentos',
        'Racioc√≠nio complexo',
        'Contexto longo (200K tokens)',
        'Streaming',
        'Function calling'
      ],
      pricing: [
        { model: 'claude-3-5-sonnet-20241022', inputCost: 0.003, outputCost: 0.015 },
        { model: 'claude-3-5-haiku-20241022', inputCost: 0.0008, outputCost: 0.004 },
        { model: 'claude-3-opus-20240229', inputCost: 0.015, outputCost: 0.075 }
      ],
      capabilities: {
        chat: true,
        vision: true,
        audio: false,
        embeddings: false,
        functionCalling: true,
        streaming: true
      },
      config: {
        baseUrl: 'https://api.anthropic.com/v1',
        timeout: 30000,
        maxRetries: 3,
        headers: {
          'Content-Type': 'application/json',
          'anthropic-version': '2023-06-01'
        }
      },
      setup: {
        requiresApiKey: true,
        apiKeyPlaceholder: 'sk-ant-...',
        apiKeyHelp: 'Sua chave API do Anthropic. Obtenha em https://console.anthropic.com/',
        additionalConfig: []
      }
    },
    {
      id: 'mistral',
      name: 'Mistral AI',
      displayName: 'Mistral AI',
      provider: AiProviderType.MISTRAL,
      description: 'Modelos Mistral 7B, Mixtral 8x7B e Codestral para conversa√ß√£o e gera√ß√£o de c√≥digo',
      icon: 'üå™Ô∏è',
      color: 'bg-cyan-100 text-cyan-800',
      models: [
        'mistral-large-latest',
        'mistral-medium-latest',
        'mistral-small-latest',
        'codestral-latest'
      ],
      features: [
        'Conversa√ß√£o eficiente',
        'Gera√ß√£o de c√≥digo',
        'Modelos compactos',
        'Streaming',
        'Baixo custo',
        'Multil√≠ngue'
      ],
      pricing: [
        { model: 'mistral-large-latest', inputCost: 0.002, outputCost: 0.006 },
        { model: 'mistral-medium-latest', inputCost: 0.0025, outputCost: 0.0075 },
        { model: 'mistral-small-latest', inputCost: 0.001, outputCost: 0.003 }
      ],
      capabilities: {
        chat: true,
        vision: false,
        audio: false,
        embeddings: true,
        functionCalling: false,
        streaming: true
      },
      config: {
        baseUrl: 'https://api.mistral.ai/v1',
        timeout: 30000,
        maxRetries: 3,
        headers: {
          'Content-Type': 'application/json'
        }
      },
      setup: {
        requiresApiKey: true,
        apiKeyPlaceholder: '...',
        apiKeyHelp: 'Sua chave API do Mistral AI. Obtenha em https://console.mistral.ai/',
        additionalConfig: []
      }
    },
    {
      id: 'cohere',
      name: 'Cohere',
      displayName: 'Cohere',
      provider: AiProviderType.COHERE,
      description: 'Modelos Command e Embed para conversa√ß√£o, an√°lise de texto e embeddings',
      icon: 'üîÆ',
      color: 'bg-pink-100 text-pink-800',
      models: [
        'command',
        'command-light',
        'command-nightly',
        'embed-english-v3.0',
        'embed-multilingual-v3.0'
      ],
      features: [
        'Conversa√ß√£o especializada',
        'An√°lise de texto',
        'Embeddings de alta qualidade',
        'Classifica√ß√£o de texto',
        'Streaming',
        'Multil√≠ngue'
      ],
      pricing: [
        { model: 'command', inputCost: 0.0015, outputCost: 0.002 },
        { model: 'command-light', inputCost: 0.0003, outputCost: 0.0006 },
        { model: 'embed-english-v3.0', inputCost: 0.0001, outputCost: 0 }
      ],
      capabilities: {
        chat: true,
        vision: false,
        audio: false,
        embeddings: true,
        functionCalling: false,
        streaming: true
      },
      config: {
        baseUrl: 'https://api.cohere.ai/v1',
        timeout: 30000,
        maxRetries: 3,
        headers: {
          'Content-Type': 'application/json'
        }
      },
      setup: {
        requiresApiKey: true,
        apiKeyPlaceholder: '...',
        apiKeyHelp: 'Sua chave API do Cohere. Obtenha em https://dashboard.cohere.ai/',
        additionalConfig: []
      }
    },
    {
      id: 'ollama',
      name: 'Ollama',
      displayName: 'Ollama (Local)',
      provider: AiProviderType.OLLAMA,
      description: 'Modelos locais Llama, Mistral e CodeLlama para uso privado e desenvolvimento',
      icon: 'üè†',
      color: 'bg-gray-100 text-gray-800',
      models: [
        'llama3.1:70b',
        'llama3.1:8b',
        'mistral:7b',
        'codellama:13b',
        'phi3:medium',
        'gemma2:9b'
      ],
      features: [
        'Execu√ß√£o local',
        'Privacidade total',
        'Sem custos de API',
        'Modelos open-source',
        'Customiza√ß√£o completa',
        'Offline'
      ],
      pricing: [
        { model: 'llama3.1:70b', inputCost: 0, outputCost: 0 },
        { model: 'llama3.1:8b', inputCost: 0, outputCost: 0 },
        { model: 'mistral:7b', inputCost: 0, outputCost: 0 }
      ],
      capabilities: {
        chat: true,
        vision: true,
        audio: false,
        embeddings: true,
        functionCalling: false,
        streaming: true
      },
      config: {
        baseUrl: 'http://localhost:11434',
        timeout: 60000,
        maxRetries: 2,
        headers: {
          'Content-Type': 'application/json'
        }
      },
      setup: {
        requiresApiKey: false,
        apiKeyPlaceholder: '',
        apiKeyHelp: 'Ollama roda localmente, n√£o requer chave API',
        additionalConfig: [
          {
            key: 'baseUrl',
            label: 'URL do Ollama',
            type: 'url',
            placeholder: 'http://localhost:11434',
            help: 'URL onde o Ollama est√° rodando',
            required: true
          }
        ]
      }
    },
    {
      id: 'huggingface',
      name: 'Hugging Face',
      displayName: 'Hugging Face',
      provider: AiProviderType.HUGGINGFACE,
      description: 'Milhares de modelos open-source para conversa√ß√£o, an√°lise de texto e embeddings',
      icon: 'ü§ó',
      color: 'bg-yellow-100 text-yellow-800',
      models: [
        'microsoft/DialoGPT-medium',
        'facebook/blenderbot-400M-distill',
        'google/flan-t5-large',
        'sentence-transformers/all-MiniLM-L6-v2',
        'microsoft/DialoGPT-large'
      ],
      features: [
        'Milhares de modelos',
        'Modelos especializados',
        'Embeddings gratuitos',
        'Modelos de pesquisa',
        'Customiza√ß√£o',
        'Open-source'
      ],
      pricing: [
        { model: 'microsoft/DialoGPT-medium', inputCost: 0.0001, outputCost: 0.0001 },
        { model: 'google/flan-t5-large', inputCost: 0.0001, outputCost: 0.0001 },
        { model: 'sentence-transformers/all-MiniLM-L6-v2', inputCost: 0.0001, outputCost: 0 }
      ],
      capabilities: {
        chat: true,
        vision: true,
        audio: true,
        embeddings: true,
        functionCalling: false,
        streaming: false
      },
      config: {
        baseUrl: 'https://api-inference.huggingface.co',
        timeout: 30000,
        maxRetries: 3,
        headers: {
          'Content-Type': 'application/json'
        }
      },
      setup: {
        requiresApiKey: true,
        apiKeyPlaceholder: 'hf_...',
        apiKeyHelp: 'Sua chave API do Hugging Face. Obtenha em https://huggingface.co/settings/tokens',
        additionalConfig: []
      }
    },
    {
      id: 'deepseek',
      name: 'DeepSeek',
      displayName: 'DeepSeek',
      provider: AiProviderType.DEEPSEEK,
      description: 'Modelos DeepSeek para conversa√ß√£o, an√°lise de c√≥digo e racioc√≠nio avan√ßado',
      icon: 'üß†',
      color: 'bg-purple-100 text-purple-800',
      models: [
        'deepseek-chat',
        'deepseek-coder',
        'deepseek-reasoner',
        'deepseek-vl'
      ],
      features: [
        'Conversa√ß√£o avan√ßada',
        'An√°lise de c√≥digo',
        'Racioc√≠nio matem√°tico',
        'Vis√£o computacional',
        'Streaming',
        'Multil√≠ngue',
        'Baixo custo',
        'Retry autom√°tico',
        'Tratamento de erros robusto'
      ],
      pricing: [
        { model: 'deepseek-chat', inputCost: 0.00014, outputCost: 0.00028 },
        { model: 'deepseek-coder', inputCost: 0.00014, outputCost: 0.00028 },
        { model: 'deepseek-reasoner', inputCost: 0.00055, outputCost: 0.00219 },
        { model: 'deepseek-vl', inputCost: 0.00014, outputCost: 0.00028 }
      ],
      capabilities: {
        chat: true,
        vision: true,
        audio: false,
        embeddings: false,
        functionCalling: false,
        streaming: true
      },
      config: {
        baseUrl: 'https://api.deepseek.com',
        timeout: 60000,
        maxRetries: 3,
        headers: {
          'Content-Type': 'application/json'
        }
      },
      setup: {
        requiresApiKey: true,
        apiKeyPlaceholder: 'sk-...',
        apiKeyHelp: 'Sua chave API do DeepSeek. Obtenha em https://platform.deepseek.com/',
        additionalConfig: []
      }
    }
  ]

  /**
   * Lista todos os templates dispon√≠veis
   */
  static getAllTemplates(): ProviderTemplate[] {
    return this.templates
  }

  /**
   * Busca template por ID
   */
  static getTemplateById(id: string): ProviderTemplate | null {
    return this.templates.find(template => template.id === id) || null
  }

  /**
   * Busca templates por provedor
   */
  static getTemplatesByProvider(provider: AiProviderType): ProviderTemplate[] {
    return this.templates.filter(template => template.provider === provider)
  }

  /**
   * Busca templates por capacidade
   */
  static getTemplatesByCapability(capability: keyof ProviderTemplate['capabilities']): ProviderTemplate[] {
    return this.templates.filter(template => template.capabilities[capability])
  }

  /**
   * Gera configura√ß√£o inicial baseada no template
   */
  static generateInitialConfig(templateId: string, apiKey?: string, additionalConfig?: Record<string, any>) {
    const template = this.getTemplateById(templateId)
    if (!template) {
      throw new Error(`Template ${templateId} not found`)
    }

    const config: any = {
      name: template.displayName,
      displayName: template.displayName,
      provider: template.provider,
      models: template.models,
      isActive: true,
      isDefault: false,
      timeout: template.config.timeout,
      maxRetries: template.config.maxRetries,
      config: {
        ...template.config,
        ...additionalConfig
      }
    }

    if (apiKey && template.setup.requiresApiKey) {
      config.apiKey = apiKey
    }

    return config
  }

  /**
   * Valida configura√ß√£o baseada no template
   */
  static validateConfig(templateId: string, config: any): { valid: boolean; errors: string[] } {
    const template = this.getTemplateById(templateId)
    if (!template) {
      return { valid: false, errors: [`Template ${templateId} not found`] }
    }

    const errors: string[] = []

    // Validar API key se necess√°rio
    if (template.setup.requiresApiKey && !config.apiKey) {
      errors.push('API key √© obrigat√≥ria para este provedor')
    }

    // Validar configura√ß√µes adicionais obrigat√≥rias
    if (template.setup.additionalConfig) {
      for (const additional of template.setup.additionalConfig) {
        if (additional.required && !config[additional.key]) {
          errors.push(`${additional.label} √© obrigat√≥rio`)
        }
      }
    }

    // Validar modelos
    if (config.models && Array.isArray(config.models)) {
      const invalidModels = config.models.filter((model: string) => !template.models.includes(model))
      if (invalidModels.length > 0) {
        errors.push(`Modelos inv√°lidos: ${invalidModels.join(', ')}`)
      }
    }

    return {
      valid: errors.length === 0,
      errors
    }
  }

  /**
   * Obt√©m estat√≠sticas dos templates
   */
  static getTemplatesStats() {
    const templates = this.getAllTemplates()
    
    return {
      total: templates.length,
      byProvider: templates.reduce((acc, template) => {
        acc[template.provider] = (acc[template.provider] || 0) + 1
        return acc
      }, {} as Record<string, number>),
      capabilities: {
        chat: templates.filter(t => t.capabilities.chat).length,
        vision: templates.filter(t => t.capabilities.vision).length,
        audio: templates.filter(t => t.capabilities.audio).length,
        embeddings: templates.filter(t => t.capabilities.embeddings).length,
        functionCalling: templates.filter(t => t.capabilities.functionCalling).length,
        streaming: templates.filter(t => t.capabilities.streaming).length
      },
      averagePricing: templates.reduce((acc, template) => {
        const avgInput = template.pricing.reduce((sum, p) => sum + p.inputCost, 0) / template.pricing.length
        const avgOutput = template.pricing.reduce((sum, p) => sum + p.outputCost, 0) / template.pricing.length
        acc.input += avgInput
        acc.output += avgOutput
        return acc
      }, { input: 0, output: 0 })
    }
  }
}
